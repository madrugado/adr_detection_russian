{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_classification import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatized_text(X):\n",
    "    lemmas = extract_lemmas(X)\n",
    "    pos_tags = load_pos_tags(\"data/resources/pos_tag_sent.txt\")\n",
    "    pos_tag_feature = create_pos_tag_feature(X, pos_tags)\n",
    "    lemmas_pos = extract_pos_lemmas(X)\n",
    "    \n",
    "    return lemmas, lemmas_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "\n",
    "f_train = \"data/folds/\" + str(i) + \"/train.txt\"\n",
    "f_test = \"data/folds/\" + str(i) + \"/test.txt\"\n",
    "X_train, y_train = load_data(f_train)\n",
    "X_test, y_test = load_data(f_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " ...]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Input, Embedding \n",
    "from keras.layers import Conv1D, GlobalMaxPool1D, MaxPool1D, LSTM, SpatialDropout1D\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens = [len(x[\"lemmas\"]) for x in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([719., 339.,  72.,  14.,   5.,   0.,   0.,   0.,   0.,   1.]),\n",
       " array([  1.,  12.,  23.,  34.,  45.,  56.,  67.,  78.,  89., 100., 111.]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 2**12\n",
    "batch_size = 512\n",
    "max_len = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [\" \".join(x[\"lemmas\"]) for x in X_train]\n",
    "test = [\" \".join(x[\"lemmas\"]) for x in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tokenizer.texts_to_sequences(train)\n",
    "x_test = tokenizer.texts_to_sequences(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pad_sequences(x_train, maxlen=max_len)\n",
    "x_test = pad_sequences(x_test, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('x_train shape:', (4598, 32))\n",
      "('x_test shape:', (1150, 32))\n"
     ]
    }
   ],
   "source": [
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ..., 1237,    6, 2579],\n",
       "       [   0,    0,    0, ...,   21,    1,  569],\n",
       "       [   0,    0,    0, ...,   17,  123,  239],\n",
       "       ...,\n",
       "       [   0,    0,    0, ..., 1465,  109,   44],\n",
       "       [   0,    0,    0, ...,  129,   54,  274],\n",
       "       [   0,    0,    0, ...,  434,   48,  378]], dtype=int32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convert class vector to binary class matrix (for use with categorical_crossentropy)\n",
      "('y_train shape:', (4598, 5))\n",
      "('y_val shape:', (1150, 5))\n"
     ]
    }
   ],
   "source": [
    "print('Convert class vector to binary class matrix '\n",
    "      '(for use with categorical_crossentropy)')\n",
    "num_classes = 5\n",
    "y_train = keras.utils.to_categorical([y-1 for y in y_train], num_classes)\n",
    "y_val = keras.utils.to_categorical([y-1 for y in y_test], num_classes)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_val shape:', y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/madrugado/Work/adr_detection_russian/venv/local/lib/python2.7/site-packages/tensorflow/python/util/deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n"
     ]
    }
   ],
   "source": [
    "main_input = Input(shape=(max_len,), dtype='int32', name='main_input')\n",
    "emb = Embedding(output_dim=128, input_dim=max_words, input_length=max_len)(main_input)\n",
    "emb = SpatialDropout1D(0.1)(emb)\n",
    "\n",
    "# tower_1 = Conv1D(64, 1, padding='same', activation='relu')(emb)\n",
    "tower_1 = Conv1D(256, 3, padding='valid', activation='relu')(emb)\n",
    "#tower_1 = LSTM(128)(tower_1)\n",
    "tower_1 = SpatialDropout1D(0.1)(tower_1)\n",
    "tower_1 = GlobalMaxPool1D()(tower_1)\n",
    "\n",
    "# tower_2 = Conv1D(64, 1, padding='same', activation='relu')(emb)\n",
    "tower_2 = Conv1D(256, 5, padding='valid', activation='relu')(emb)\n",
    "#tower_2 = LSTM(128)(tower_2)\n",
    "tower_2 = SpatialDropout1D(0.1)(tower_2)\n",
    "tower_2 = GlobalMaxPool1D()(tower_2)\n",
    "\n",
    "# tower_3 = MaxPool1D(3, padding='same')(emb)\n",
    "tower_3 = Conv1D(256, 7, padding='valid', activation='relu')(emb)\n",
    "#tower_3 = LSTM(128)(tower_3)\n",
    "tower_3 = SpatialDropout1D(0.1)(tower_3)\n",
    "tower_3 = GlobalMaxPool1D()(tower_3)\n",
    "\n",
    "#aux_input = Input(shape=(50,), dtype='float', name='aux_input')\n",
    "output = keras.layers.concatenate([tower_1, tower_2, tower_3], axis=1)\n",
    "# output = Dropout(0.1)(output)\n",
    "#output = keras.layers.concatenate([output, aux_input], axis=1)\n",
    "sm = Dense(num_classes, activation='softmax')(output)\n",
    "\n",
    "model = Model(inputs=main_input, outputs=sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.topology.InputLayer at 0x7f8ba4044090>,\n",
       " <keras.layers.embeddings.Embedding at 0x7f8ba4044050>,\n",
       " <keras.layers.core.SpatialDropout1D at 0x7f8bf82bcc10>,\n",
       " <keras.layers.convolutional.Conv1D at 0x7f8ba40efe90>,\n",
       " <keras.layers.convolutional.Conv1D at 0x7f8ba4044450>,\n",
       " <keras.layers.convolutional.Conv1D at 0x7f8ba3e76a10>,\n",
       " <keras.layers.core.SpatialDropout1D at 0x7f8ba4044290>,\n",
       " <keras.layers.core.SpatialDropout1D at 0x7f8ba3eddbd0>,\n",
       " <keras.layers.core.SpatialDropout1D at 0x7f8ba3ea4d10>,\n",
       " <keras.layers.pooling.GlobalMaxPooling1D at 0x7f8bf8431b90>,\n",
       " <keras.layers.pooling.GlobalMaxPooling1D at 0x7f8ba3e76c50>,\n",
       " <keras.layers.pooling.GlobalMaxPooling1D at 0x7f8ba3e6eb90>,\n",
       " <keras.layers.merge.Concatenate at 0x7f8ba3bca0d0>,\n",
       " <keras.layers.core.Dense at 0x7f8ba3bfca90>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.objectives import categorical_crossentropy\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/madrugado/Work/adr_detection_russian/venv/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "Train on 4138 samples, validate on 460 samples\n",
      "Epoch 1/10\n",
      "4138/4138 [==============================] - 1s 248us/step - loss: 1.2457 - categorical_accuracy: 0.6890 - val_loss: 0.8204 - val_categorical_accuracy: 0.7717\n",
      "Epoch 2/10\n",
      "4138/4138 [==============================] - 0s 36us/step - loss: 0.8274 - categorical_accuracy: 0.7811 - val_loss: 0.7944 - val_categorical_accuracy: 0.7717\n",
      "Epoch 3/10\n",
      "4138/4138 [==============================] - 0s 36us/step - loss: 0.7474 - categorical_accuracy: 0.7811 - val_loss: 0.7685 - val_categorical_accuracy: 0.7717\n",
      "Epoch 4/10\n",
      "4138/4138 [==============================] - 0s 34us/step - loss: 0.7071 - categorical_accuracy: 0.7811 - val_loss: 0.7269 - val_categorical_accuracy: 0.7717\n",
      "Epoch 5/10\n",
      "4138/4138 [==============================] - 0s 35us/step - loss: 0.6537 - categorical_accuracy: 0.7815 - val_loss: 0.6833 - val_categorical_accuracy: 0.7739\n",
      "Epoch 6/10\n",
      "4138/4138 [==============================] - 0s 34us/step - loss: 0.5799 - categorical_accuracy: 0.7994 - val_loss: 0.6446 - val_categorical_accuracy: 0.7848\n",
      "Epoch 7/10\n",
      "4138/4138 [==============================] - 0s 35us/step - loss: 0.5030 - categorical_accuracy: 0.8325 - val_loss: 0.6157 - val_categorical_accuracy: 0.7804\n",
      "Epoch 8/10\n",
      "4138/4138 [==============================] - 0s 34us/step - loss: 0.4244 - categorical_accuracy: 0.8487 - val_loss: 0.6072 - val_categorical_accuracy: 0.7826\n",
      "Epoch 9/10\n",
      "4138/4138 [==============================] - 0s 34us/step - loss: 0.3552 - categorical_accuracy: 0.8833 - val_loss: 0.6196 - val_categorical_accuracy: 0.7870\n",
      "Epoch 10/10\n",
      "4138/4138 [==============================] - 0s 34us/step - loss: 0.2911 - categorical_accuracy: 0.8995 - val_loss: 0.6538 - val_categorical_accuracy: 0.7826\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import TensorBoard  \n",
    "tensorboard=TensorBoard(log_dir='./logs', write_graph=True, write_images=True)\n",
    "from keras.callbacks import EarlyStopping  \n",
    "early_stopping=EarlyStopping(monitor='val_loss', patience=3)  \n",
    "\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[tensorboard, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4138 samples, validate on 460 samples\n",
      "Epoch 1/10\n",
      "4138/4138 [==============================] - 0s 34us/step - loss: 0.2372 - categorical_accuracy: 0.9246 - val_loss: 0.6837 - val_categorical_accuracy: 0.7913\n",
      "Epoch 2/10\n",
      "4138/4138 [==============================] - 0s 35us/step - loss: 0.1895 - categorical_accuracy: 0.9456 - val_loss: 0.7224 - val_categorical_accuracy: 0.7783\n",
      "Epoch 3/10\n",
      "4138/4138 [==============================] - 0s 34us/step - loss: 0.1563 - categorical_accuracy: 0.9560 - val_loss: 0.7627 - val_categorical_accuracy: 0.7783\n",
      "Epoch 4/10\n",
      "4138/4138 [==============================] - 0s 35us/step - loss: 0.1269 - categorical_accuracy: 0.9671 - val_loss: 0.8151 - val_categorical_accuracy: 0.7826\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import TensorBoard  \n",
    "tensorboard=TensorBoard(log_dir='./logs', write_graph=True, write_images=True)\n",
    "from keras.callbacks import EarlyStopping  \n",
    "early_stopping=EarlyStopping(monitor='val_loss', patience=3)  \n",
    "\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[tensorboard, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1150/1150 [==============================] - 0s 18us/step\n",
      "\n",
      "\n",
      "('Test score:', 0.6857468864192133)\n",
      "('Test accuracy:', 0.7930434762913248)\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_val, batch_size=batch_size, verbose=1)\n",
    "print('\\n')\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1150/1150 [==============================] - 0s 52us/step\n"
     ]
    }
   ],
   "source": [
    "results = model.predict(x_test, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1150/1150 [==============================] - 0s 12us/step\n"
     ]
    }
   ],
   "source": [
    "results = model.predict(x_test, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0      0.414     0.203     0.273        59\n",
      "          1      0.512     0.323     0.396       133\n",
      "          2      0.854     0.908     0.880       901\n",
      "          3      0.000     0.000     0.000         0\n",
      "          4      0.652     0.263     0.375        57\n",
      "\n",
      "avg / total      0.782     0.772     0.768      1150\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/madrugado/Work/adr_detection_russian/venv/local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/madrugado/Work/adr_detection_russian/venv/local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val, np.round(results), digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4863467982680296\n",
      "0.3395472258214716\n",
      "0.38481673413435197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/madrugado/Work/adr_detection_russian/venv/local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/madrugado/Work/adr_detection_russian/venv/local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/home/madrugado/Work/adr_detection_russian/venv/local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/madrugado/Work/adr_detection_russian/venv/local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(metrics.precision_score(y_val, np.round(results), average='macro'))\n",
    "print(metrics.recall_score(y_val, np.round(results), average='macro'))\n",
    "print(metrics.f1_score(y_val, np.round(results), average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
